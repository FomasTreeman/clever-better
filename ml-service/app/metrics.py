"""Prometheus metrics for ML service."""
from __future__ import annotations

from prometheus_client import Counter, Histogram, Gauge


# Prediction metrics
prediction_counter = Counter(
    'ml_predictions_total',
    'Total number of predictions made',
    ['model_name', 'status']
)

prediction_latency = Histogram(
    'ml_prediction_latency_seconds',
    'Prediction latency in seconds',
    ['model_name']
)

prediction_confidence = Gauge(
    'ml_prediction_confidence',
    'Confidence of last prediction',
    ['model_name']
)

# Training metrics
training_counter = Counter(
    'ml_training_jobs_total',
    'Total number of training jobs',
    ['model_type', 'status']
)

training_duration = Histogram(
    'ml_training_duration_seconds',
    'Training duration in seconds',
    ['model_type']
)

model_accuracy = Gauge(
    'ml_model_accuracy',
    'Model accuracy metric',
    ['model_name', 'dataset']
)

# Model registry metrics
registered_models = Gauge(
    'ml_registered_models_total',
    'Total number of registered models'
)

# Cache metrics
cache_hit_ratio = Gauge(
    'ml_cache_hit_ratio',
    'Cache hit ratio for ML predictions'
)

cache_size = Gauge(
    'ml_cache_size_bytes',
    'Size of ML prediction cache in bytes'
)

# Backtest metrics
backtest_counter = Counter(
    'ml_backtest_runs_total',
    'Total backtest runs executed',
    ['method', 'status']
)

backtest_duration = Histogram(
    'ml_backtest_duration_seconds',
    'Backtest execution duration in seconds',
    ['method']
)

# Strategy generation metrics
strategy_generation_counter = Counter(
    'ml_strategies_generated_total',
    'Total strategies generated by ML'
)

strategy_generation_duration = Histogram(
    'ml_strategy_generation_duration_seconds',
    'Time taken to generate strategies'
)

model_versions = Gauge(
    'ml_model_versions',
    'Number of versions per model',
    ['model_name']
)


# Helper functions
def record_prediction(model_name: str, duration_seconds: float, status: str = 'success'):
    """Record a prediction event."""
    prediction_counter.labels(model_name=model_name, status=status).inc()
    prediction_latency.labels(model_name=model_name).observe(duration_seconds)


def record_training_job(model_type: str, duration_seconds: float, status: str = 'success'):
    """Record a training job completion."""
    training_counter.labels(model_type=model_type, status=status).inc()
    training_duration.labels(model_type=model_type).observe(duration_seconds)


def update_model_accuracy(model_name: str, accuracy: float, dataset: str = 'test'):
    """Update the model accuracy."""
    model_accuracy.labels(model_name=model_name, dataset=dataset).set(accuracy)


def update_cache_hit_ratio(ratio: float):
    """Update the cache hit ratio."""
    cache_hit_ratio.set(ratio)


def update_cache_size(size_bytes: int):
    """Update the cache size."""
    cache_size.set(size_bytes)


def record_backtest_run(method: str, duration_seconds: float, status: str = 'success'):
    """Record a backtest run."""
    backtest_counter.labels(method=method, status=status).inc()
    backtest_duration.labels(method=method).observe(duration_seconds)


def record_strategy_generation(duration_seconds: float):
    """Record a strategy generation event."""
    strategy_generation_counter.inc()
    strategy_generation_duration.observe(duration_seconds)
